{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuhyIvzgHHAXYqMzq2Weyq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trainocate-japan/extending_genai_with_langchain/blob/main/chapter3/exercise1/exercise1_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 演習の準備\n",
        "---"
      ],
      "metadata": {
        "id": "2SXS3qjHO5J9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 必要なライブラリのインストール"
      ],
      "metadata": {
        "id": "Atc5HQiZ58vA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q langchain langchain-core langchain-openai langchain-community"
      ],
      "metadata": {
        "id": "xNJhQoCptr7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain==0.3.7 langchain-openai==0.2.9 langchain-community==0.3.7 langchain-core==0.3.18 langchain-text-splitters==0.3.2"
      ],
      "metadata": {
        "id": "5L-ErUJuMtEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API キーの設定\n",
        "*  左ナビゲーションで [**シークレット**] アイコン (鍵形のアイコン) をクリックします。\n",
        "*  [**新しいシークレットを追加**] をクリックし、[**名前**] に `OPENAI_API_KEY` と入力し、その [**値**] に指定されたキーを入力します。\n",
        "*  [**新しいシークレットを追加**] をクリックし、[**名前**] に `LANGCHAIN_API_KEY` と入力し、その [**値**] に LangSmith で作成してコピーしておいた API キーを入力します。\n",
        "*  設定した 2 つのシークレットの [**ノートブックからのアクセス**] を有効にします。\n",
        "*  入力が完了したら、下のセルを実行します。"
      ],
      "metadata": {
        "id": "AzQOWZ8y6KU-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3-Ha_aLspoO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"default\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 演習 1.1 会話履歴を保持しないチャットアプリ\n",
        "---\n",
        "各タスク (Task:) のコードを実装しながらセルを順次実行してください。"
      ],
      "metadata": {
        "id": "_fnz23NjFQBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "OXlCRqlqNNGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** Chat model のインスタンスを作成してください\n",
        "* モデルのタイプ: OpenAI の `gpt-4o-mini`\n",
        "* temperature: `0`\n",
        "\n",
        "[langchain_openai.chat_models.base.ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)"
      ],
      "metadata": {
        "id": "gQ85uYKENSqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "kcF7FBmqO535"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** プロンプトのテンプレートを作成してください  \n",
        "* SystemMessage と HumanMessage からテンプレートを作成します\n",
        "* SystemMessage: 何か特定の分野についての専門性をもち、ユーザーの質問の回答するように指示してください (分野はお好きなもので構いません)\n",
        "* HumanMessage: 後でユーザーの入力を代入できるように `{question}` という変数にしてください\n",
        "\n",
        "[langchain_core.prompts.prompt.PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html)"
      ],
      "metadata": {
        "id": "DxuZRxflPCDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\n",
        "        \"system\",\n",
        "        \"あなたはプログラミング言語 Python の高度なスキルをもつプロフェッショナルのエンジニアです。次の質問に答えてください：\"\n",
        "    ),\n",
        "    (\n",
        "        \"human\",\n",
        "        \"{question}\"\n",
        "    )\n",
        "])"
      ],
      "metadata": {
        "id": "QhaOWAngRr05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** LLM の回答をテキストの形式に変換する Output parser のインスタンスを作成してください\n",
        "\n",
        "[langchain_core.output_parsers.string.StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html)"
      ],
      "metadata": {
        "id": "L95ZN19wTDzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "q8hnhIuzZUzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** `chat_prompt` > `model` > `parser` の順で処理を実行する Chain を定義してください"
      ],
      "metadata": {
        "id": "mgvA0guwZUVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = chat_prompt | model | parser"
      ],
      "metadata": {
        "id": "ZK0B7Pe9YGYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行して動作を確認してください"
      ],
      "metadata": {
        "id": "X0ulvRiPbWGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Write Quit, Exit or Bye to quit.')\n",
        "while True:\n",
        "    q = input('Your prompt: ')\n",
        "    if q.lower() in ['quit', 'exit', 'bye']:\n",
        "        print('Quitting ... bye bye!')\n",
        "        break\n",
        "\n",
        "    answer = chain.invoke({\"question\": q})\n",
        "    print(f'\\nAnswer: {answer}')"
      ],
      "metadata": {
        "id": "HvqfNw22bUV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangSmish でトレース結果を参照し、想定した処理が実行されていたか確認してください。"
      ],
      "metadata": {
        "id": "OEw7h_xbC5tE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 演習 1.2 会話履歴を保持するチャットアプリ\n",
        "---\n",
        "下のセル内の各タスク (Task:) のコードを実装してください。  \n",
        "\n",
        "[langchain_core.runnables.history.RunnableWithMessageHistory](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html)  \n",
        "[How to add memory to chatbots](https://python.langchain.com/docs/how_to/chatbots_memory/)"
      ],
      "metadata": {
        "id": "9JW3TX082wrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.chat_message_histories.in_memory import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "# Task:\n",
        "# Chat model のインスタンスを作成\n",
        "# ・OpenAI の gpt-4o-mini を使用\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "\n",
        "# Task:\n",
        "# 特定のセッション ID に対する会話履歴を取得する関数を作成\n",
        "# ・ChatMessageHistory を使用\n",
        "\n",
        "store = {}\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "\n",
        "# Task:\n",
        "# Prompt template を作成\n",
        "# ・SystemMessage と HumanMessage からテンプレートを作成します\n",
        "# ・SystemMessage: 何か特定の分野についての専門性をもち、ユーザーの質問の回答するように指示します (分野はお好きなもので構いません)\n",
        "# ・HumanMessage: 後でユーザーの入力を代入できるように {input} という変数にします\n",
        "# ・MessgePlaceholder を使用してプロンプトに会話履歴を含めるようにします\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages(\n",
        "  [\n",
        "      SystemMessagePromptTemplate.from_template(\"あなたはプログラミング言語 Python の高度なスキルをもつプロフェッショナルのエンジニアです。次の質問に答えてください：\"),\n",
        "      MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "      HumanMessagePromptTemplate.from_template(\"{input}\")\n",
        "  ]\n",
        ")\n",
        "\n",
        "\n",
        "# Task:\n",
        "# Output parser を作成\n",
        "# ・LLM からの出力をテキスト形式に変換する Output Parser のインスタンスを作成します\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "\n",
        "# Task:\n",
        "# Chain を定義する\n",
        "\n",
        "chain = chat_prompt | model | parser\n",
        "\n",
        "\n",
        "# Task:\n",
        "# RunnableWithMessageHistory を使用して、chain の処理に会話履歴が組み込まれるように実装してください\n",
        "\n",
        "runnable_with_history = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        ")"
      ],
      "metadata": {
        "id": "MShzrcWT4wtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行して動作を確認してください"
      ],
      "metadata": {
        "id": "vewijiJbqhON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Write Quit, Exit or Bye to quit.')\n",
        "while True:\n",
        "    q = input('Your prompt: ')\n",
        "    if q.lower() in ['quit', 'exit', 'bye']:\n",
        "        print('Quitting ... bye bye!')\n",
        "        break\n",
        "\n",
        "    answer = runnable_with_history.invoke({\"input\": q}, config={\"configurable\": {\"session_id\": \"a789\"}})\n",
        "    print(f'\\nAnswer: {answer}')"
      ],
      "metadata": {
        "id": "XLeSBxDkoji3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangSmish でトレース結果を参照し、想定した処理が実行されていたか確認してください。"
      ],
      "metadata": {
        "id": "w90dss0gC8jR"
      }
    }
  ]
}