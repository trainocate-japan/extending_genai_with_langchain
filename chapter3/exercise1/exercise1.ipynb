{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyObCQTsQ7uYOt4LW+koCNNV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trainocate-japan/extending_genai_with_langchain/blob/main/chapter3/exercise1/exercise1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 演習の準備\n",
        "---"
      ],
      "metadata": {
        "id": "2SXS3qjHO5J9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 必要なライブラリのインストール"
      ],
      "metadata": {
        "id": "Atc5HQiZ58vA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q langchain langchain-core langchain-openai langchain-community"
      ],
      "metadata": {
        "id": "xNJhQoCptr7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain==0.3.4 langchain-openai==0.2.3 langchain-community==0.3.3 langchain-core==0.3.12 langchain-text-splitters==0.3.0"
      ],
      "metadata": {
        "id": "5L-ErUJuMtEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API キーの設定\n",
        "*  左ナビゲーションで [**シークレット**] アイコン (鍵形のアイコン) をクリックします。\n",
        "*  [**新しいシークレットを追加**] をクリックし、[**名前**] に `OPENAI_API_KEY` と入力し、その [**値**] に指定されたキーを入力します。\n",
        "*  [**新しいシークレットを追加**] をクリックし、[**名前**] に `LANGCHAIN_API_KEY` と入力し、その [**値**] に LangSmith で作成してコピーしておいた API キーを入力します。\n",
        "*  設定した 2 つのシークレットの [**ノートブックからのアクセス**] を有効にします。\n",
        "*  入力が完了したら、下のセルを実行します。"
      ],
      "metadata": {
        "id": "AzQOWZ8y6KU-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3-Ha_aLspoO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"default\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 演習 1.1 会話履歴を保持しないチャットアプリ\n",
        "---\n",
        "各タスク (Task:) のコードを実装しながらセルを順次実行してください。"
      ],
      "metadata": {
        "id": "_fnz23NjFQBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "OXlCRqlqNNGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** Chat model のインスタンスを作成してください\n",
        "* モデルのタイプ: OpenAI の `gpt-4o-mini`\n",
        "* temperature: `0`\n",
        "\n",
        "[langchain_openai.chat_models.base.ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)"
      ],
      "metadata": {
        "id": "gQ85uYKENSqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model ="
      ],
      "metadata": {
        "id": "kcF7FBmqO535"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** プロンプトのテンプレートを作成してください  \n",
        "* SystemMessage と HumanMessage からテンプレートを作成します\n",
        "* SystemMessage: 何か特定の分野についての専門性をもち、ユーザーの質問の回答するように指示してください (分野はお好きなもので構いません)\n",
        "* HumanMessage: 後でユーザーの入力を代入できるように `{question}` という変数にしてください\n",
        "\n",
        "[langchain_core.prompts.prompt.PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html)"
      ],
      "metadata": {
        "id": "DxuZRxflPCDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt ="
      ],
      "metadata": {
        "id": "QhaOWAngRr05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** LLM の回答をテキストの形式に変換する Output parser のインスタンスを作成してください\n",
        "\n",
        "[langchain_core.output_parsers.string.StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html)"
      ],
      "metadata": {
        "id": "L95ZN19wTDzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser ="
      ],
      "metadata": {
        "id": "q8hnhIuzZUzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** `chat_prompt` > `model` > `parser` の順で処理を実行する Chain を定義してください"
      ],
      "metadata": {
        "id": "mgvA0guwZUVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain ="
      ],
      "metadata": {
        "id": "ZK0B7Pe9YGYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行して動作を確認してください"
      ],
      "metadata": {
        "id": "X0ulvRiPbWGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Write Quit, Exit or Bye to quit.')\n",
        "while True:\n",
        "    q = input('Your prompt: ')\n",
        "    if q.lower() in ['quit', 'exit', 'bye']:\n",
        "        print('Quitting ... bye bye!')\n",
        "        break\n",
        "\n",
        "    answer = chain.invoke({\"question\": q})\n",
        "    print(f'\\nAnswer: {answer}')"
      ],
      "metadata": {
        "id": "HvqfNw22bUV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangSmish でトレース結果を参照し、想定した処理が実行されていたか確認してください。"
      ],
      "metadata": {
        "id": "KPQOcSKYBPME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 演習 2.2 会話履歴を保持するチャットアプリ\n",
        "---\n",
        "下のセル内の各タスク (Task:) のコードを実装してください。  \n",
        "\n",
        "[langchain_core.runnables.history.RunnableWithMessageHistory](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html)  \n",
        "[How to add memory to chatbots](https://python.langchain.com/docs/how_to/chatbots_memory/)"
      ],
      "metadata": {
        "id": "9JW3TX082wrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.chat_message_histories.in_memory import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "# Task:\n",
        "# Chat model のインスタンスを作成\n",
        "# ・OpenAI の gpt-4o-mini を使用\n",
        "\n",
        "model =\n",
        "\n",
        "\n",
        "# Task:\n",
        "# 特定のセッション ID に対する会話履歴を取得する関数を作成\n",
        "# ・ChatMessageHistory を使用\n",
        "\n",
        "store = {}\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] =\n",
        "    return store[session_id]\n",
        "\n",
        "\n",
        "# Task:\n",
        "# Prompt template を作成\n",
        "# ・SystemMessage と HumanMessage からテンプレートを作成します\n",
        "# ・SystemMessage: 何か特定の分野についての専門性をもち、ユーザーの質問の回答するように指示します (分野はお好きなもので構いません)\n",
        "# ・HumanMessage: 後でユーザーの入力を代入できるように {input} という変数にします\n",
        "# ・MessgePlaceholder を使用してプロンプトに会話履歴を含めるようにします\n",
        "\n",
        "chat_prompt =\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Task:\n",
        "# Output parser を作成\n",
        "# ・LLM からの出力をテキスト形式に変換する Output Parser のインスタンスを作成します\n",
        "\n",
        "parser =\n",
        "\n",
        "\n",
        "# Task:\n",
        "# Chain を定義する\n",
        "\n",
        "chain =\n",
        "\n",
        "\n",
        "# Task:\n",
        "# RunnableWithMessageHistory を使用して、chain の処理に会話履歴が組み込まれるように実装してください\n",
        "\n",
        "runnable_with_history =\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MShzrcWT4wtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行して動作を確認してください"
      ],
      "metadata": {
        "id": "vewijiJbqhON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Write Quit, Exit or Bye to quit.')\n",
        "while True:\n",
        "    q = input('Your prompt: ')\n",
        "    if q.lower() in ['quit', 'exit', 'bye']:\n",
        "        print('Quitting ... bye bye!')\n",
        "        break\n",
        "\n",
        "    answer = runnable_with_history.invoke({\"input\": q}, config={\"configurable\": {\"session_id\": \"b123\"}})\n",
        "    print(f'\\nAnswer: {answer}')"
      ],
      "metadata": {
        "id": "XLeSBxDkoji3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangSmish でトレース結果を参照し、想定した処理が実行されていたか確認してください。"
      ],
      "metadata": {
        "id": "f7nhJ_MYBpXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "お時間に余裕のある方は、プロンプトをいろいろ変えて試してみてください。  \n",
        "コードを変更していただいても構いません。"
      ],
      "metadata": {
        "id": "w-a0xLkFAy-g"
      }
    }
  ]
}