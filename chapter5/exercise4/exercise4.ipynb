{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMN6Mu0aYb9Pww97XgnWGcF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trainocate-japan/extending_genai_with_langchain/blob/main/chapter5/exercise4/exercise4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 演習の準備\n",
        "---"
      ],
      "metadata": {
        "id": "2SXS3qjHO5J9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 必要なライブラリのインストール"
      ],
      "metadata": {
        "id": "hjpQpmcrkcA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-openai langchain-community langchainhub langgraph tavily-python chromadb tiktoken"
      ],
      "metadata": {
        "id": "xNJhQoCptr7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q langchain==0.3.0 langchain-community==0.3.0 langchain-core==0.3.1 langchain-openai==0.2.0 langchain-text-splitters==0.3.0 langgraph==0.2.22 langgraph-checkpoint==1.0.10 langchainhub==0.1.21 tavily-python chromadb tiktoken"
      ],
      "metadata": {
        "id": "5L-ErUJuMtEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API キーの設定\n",
        "*  左ナビゲーションで [**シークレット**] アイコン (鍵形のアイコン) をクリックします。\n",
        "*  [**新しいシークレットを追加**] をクリックし、`LANGCHAIN_API_KEY`、`OPENAI_API_KEY`、`TAVILY_API_KEY` の 3 つを設定し、[**ノートブックからのアクセス**] を有効にします\n",
        "  *  `OPENAI_API_KEY` の [**値**] には指定されたキーを入力します。\n",
        "  *  `LANGCHAIN_API_KEY` と `TAVILY_API_KEY` の [**値**] にはご自身で取得したキーを入力してください。\n",
        "*  入力が完了したら、下のセルを実行します。"
      ],
      "metadata": {
        "id": "7Xq-T4gzi4ga"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3-Ha_aLspoO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"default\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "pclZg_IOh173"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web 検索して回答するエージェントの作成\n",
        "---\n",
        "ユーザーの質問に対して、必要に応じて Web 検索を実行して回答するチャットエージェントを LangGraph を使って作成します。  \n",
        "タスク (Task) になっている各セルのコードの不足している部分を補完して処理を実装してください。  \n",
        "  \n",
        "ハンズオン (**implement_agents.ipynb**) のコードを参考にしてください。  \n",
        "解答は **exercise4_solution.ipynb** に記載されています。  \n",
        "  \n",
        "https://langchain-ai.github.io/langgraph/  \n",
        "[Intro to LangGraph](https://langchain-ai.github.io/langgraph/tutorials/introduction/)"
      ],
      "metadata": {
        "id": "IORhWlqn8Fgl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task: Tool を用意する\n",
        "Tavily Search で Web 検索を行う Tool を作成します。\n",
        "*  `TavilySearchResults` を使用します\n",
        "*  取得する検索結果の最大数は任意に設定して構いません (最終的な実行結果に応じて後から調整してみてください)\n",
        "*  `TavilySearchResults` のインスタンスを要素とするリストを作成します\n",
        "\n",
        "[langchain_community.tools.tavily_search.tool.TavilySearchResults](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.tavily_search.tool.TavilySearchResults.html)"
      ],
      "metadata": {
        "id": "lCLDIgFdQwtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "# TavilySearchResults のインスタンスを作成\n",
        "tool =\n",
        "\n",
        "# Tool のリストを作成\n",
        "tools =\n",
        "\n",
        "# Tool の動作を確認する\n",
        "# 適当な質問を入力して検索結果が返ってくることを確認してください\n",
        "tool.invoke(\"LangGraph におけるノードとは何ですか。\")"
      ],
      "metadata": {
        "id": "WedKS69VpIPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task: State を定義して Graph のインスタンスを作成する\n",
        "* State はリストでデータを保持し、`add_message` 関数でデータを追加するように設定します\n",
        "* Graph には `StateGraph` を使用します"
      ],
      "metadata": {
        "id": "G9uRIc3gP4U4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "# State を定義する\n",
        "class State(TypedDict):\n",
        "\n",
        "\n",
        "# Graph (StateGraph) のインスタンスを作成する\n",
        "graph_builder ="
      ],
      "metadata": {
        "id": "VFhLPHBIoPpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task: Chat model に Tool の情報を渡す\n",
        "* Chat model には OpenAI の `gpt-4o-mini` を使用します\n",
        "* Chat model のインスタンスに Tool のリスト `tools` をバインドして Tool の情報を渡します"
      ],
      "metadata": {
        "id": "z9x3R7QrQ1_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chat model のインスタンスを作成する\n",
        "model =\n",
        "\n",
        "# 使用できる Tool の情報を Chat model 渡す\n",
        "## 上で作成した Tool のリストをバインドする\n",
        "llm_with_tools ="
      ],
      "metadata": {
        "id": "m5jNeFcJQcuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task: Chat model で LLM を呼び出す Node を Graph に追加する\n",
        "* 上で作成した、Tool がバインドされた Chat model で LLM を呼び出す処理を実行する関数を定義します\n",
        "* その関数を `chatbot` という名前の Node として Graph に追加します"
      ],
      "metadata": {
        "id": "PhBovN8xSUYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM を呼び出す関数を定義する\n",
        "def chatbot(state: State):\n",
        "\n",
        "\n",
        "# Node を Graph に追加する\n",
        "graph_builder."
      ],
      "metadata": {
        "id": "vxvg2IvcSSsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task: Tool で Web 検索を実行する Node を追加する\n",
        "\n",
        "* この演習では、検索処理の関数は自身で作成せずに、LangGraph に予め用意されている `ToolNode` を使用します\n",
        "* `ToolNode` のインスタンスを `tools` という名前の Node として Graph に追加します\n",
        "\n",
        "[ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode)"
      ],
      "metadata": {
        "id": "JfEBFzkK1Dpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from    import\n",
        "\n",
        "# ToolNode のインスタンスを作成する\n",
        "## 上で作成した Tool をリストで渡す\n",
        "tool_node =\n",
        "\n",
        "# Node を Graph に追加\n",
        "graph_builder."
      ],
      "metadata": {
        "id": "RGO8NfWZzlL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task: Web 検索する場合に Node `tools` にルーティングする Edge を追加する\n",
        "Node `chatbot` の処理で Web 検索すると判断された場合に、処理を Node `tools` にルーティングする Edge を作成します。\n",
        "\n",
        "* この演習では、条件分岐の関数は自身で作成せずに、LangGraph に予め用意されている `tools_conditon` 関数を使用します\n",
        "* Node `chatbot` に条件つき Edge を追加します\n",
        "\n",
        "[tools_condition](https://langchain-ai.github.io/langgraph/reference/prebuilt/?#tools_condition)"
      ],
      "metadata": {
        "id": "C4wVuswe2lad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from    import\n",
        "\n",
        "# Edge を Graph に追加\n",
        "## Node \"chatbot\" の処理後に条件分岐を行う\n",
        "graph_builder.\n",
        "\n"
      ],
      "metadata": {
        "id": "CJQgiy_X136L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task: エントリーポイントを設定する\n",
        "* Node `tools` から Node `chatbot` に処理をルーティングする Edge を Graph に追加します\n",
        "* Node `chatbot` を Graph のエントリーポイントとして設定します"
      ],
      "metadata": {
        "id": "VX47pIzn48gE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tools → chatbot への Edge を追加\n",
        "graph_builder.\n",
        "\n",
        "# エントリーポイントをセット\n",
        "graph_builder."
      ],
      "metadata": {
        "id": "9HPu1O_bUlH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task: チャット エージェントが会話履歴を保持するように Chekpointer を構成する\n",
        "* この演習では、インメモリに会話履歴データを保存する `MemorySaver` を使用します\n",
        "* `MemorySaver` のインスタンスを作成します\n",
        "\n",
        "[MemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#memorysaver)"
      ],
      "metadata": {
        "id": "qZ4fHB5I6X5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from    import\n",
        "\n",
        "memory ="
      ],
      "metadata": {
        "id": "RQbyn1Go63ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task: Graph をコンパイルする\n",
        "* 上で作成した Checkpointer を指定して Graph をコンパイルします"
      ],
      "metadata": {
        "id": "aM7GQIpq6BG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph をコンパイル\n",
        "graph = graph_builder."
      ],
      "metadata": {
        "id": "P1kx8ygJ6TTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph を可視化する"
      ],
      "metadata": {
        "id": "JLbUS7A4NF_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "id": "yjxo_JyvUtLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 会話のスレッド ID を設定する"
      ],
      "metadata": {
        "id": "epNU8HMrDef0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"1\"}}"
      ],
      "metadata": {
        "id": "IZmXPnjbDYV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task: チャットエージェントをインタラクティブに実行する\n",
        "* ユーザーの入力、`config` 、`stream_mode` を渡して Graph を実行します\n",
        "* `stream_mode` は `values` を指定します"
      ],
      "metadata": {
        "id": "bTKLhx41NbLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "    response =\n",
        "    print(\"Assistant:\", response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "RgAOecx-lcNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "この演習の実装では、LLM にユーザーの質問だけがそのまま入力されるため、Web 検索によって適切なドキュメントが与えられても必ずしも回答の精度は高くありません。プロンプト設計が非常に重要であることがわかります。  \n",
        "\n",
        "エージェントの処理や回答の精度を上げるには、プロンプト設計を行う、処理に応じた複数の Tool を使用する、各 Node の処理をより複雑な Chian として構成するなどの実装が必要になります。複数のエージェントを組み合わせるマルチエージェント構成が必要になることもあるでしょう。  \n",
        "\n",
        "今後の学習として、LangGraph の公式ドキュメントにあるより応用的なチュートリアルを試してみてください。  \n",
        "\n",
        "[Build a Customer Support Bot](https://langchain-ai.github.io/langgraph/tutorials/customer-support/customer-support/)  \n",
        "[Code Assistant](https://langchain-ai.github.io/langgraph/tutorials/code_assistant/langgraph_code_assistant/)  \n",
        "[Agentic RAG](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/)  \n",
        "\n",
        "マルチエージェント  \n",
        "[Basic Multi-Agent Collaboration](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/)  \n",
        "[Hierarchical Teams](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/)"
      ],
      "metadata": {
        "id": "U2IqXBWQKVFm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## まとめたコード\n",
        "上では、コードを複数のセルに細かく分けていました。  \n",
        "下のセルには、同じコードがまとめて記載されています。時間に余裕があれば、下のセルのコードも補完してみてください。  \n",
        "\n",
        "※ 最初にコードのコメントアウトを解除してください。コード全体を選択して `Ctrl`+`/` で解除できます。"
      ],
      "metadata": {
        "id": "KyHCdT3gPRAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from typing import Annotated\n",
        "# from typing_extensions import TypedDict\n",
        "\n",
        "# from langchain_openai import ChatOpenAI\n",
        "# from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "# from langchain_core.messages import BaseMessage\n",
        "\n",
        "# from langgraph.graph import StateGraph\n",
        "# from langgraph.graph.message import add_messages\n",
        "# from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "# from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "\n",
        "# class State(TypedDict):\n",
        "#     messages: Annotated[list, add_messages]\n",
        "\n",
        "# graph_builder = StateGraph(State)\n",
        "\n",
        "# tool = TavilySearchResults(max_results=5)\n",
        "# tools = [tool]\n",
        "# model = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
        "# llm_with_tools = model.bind_tools(tools)\n",
        "\n",
        "# def chatbot(state: State):\n",
        "#     return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "# graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "# tool_node = ToolNode(tools=[tool])\n",
        "# graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "# graph_builder.add_conditional_edges(\n",
        "#     \"chatbot\",\n",
        "#     tools_condition,\n",
        "# )\n",
        "\n",
        "# graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "# graph_builder.set_entry_point(\"chatbot\")\n",
        "\n",
        "# memory = MemorySaver()\n",
        "\n",
        "# graph = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "# config = {\"configurable\": {\"thread_id\": \"2\"}}"
      ],
      "metadata": {
        "id": "v4-6WZrL6V1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# while True:\n",
        "#     user_input = input(\"User: \")\n",
        "#     if user_input.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
        "#         print(\"Goodbye!\")\n",
        "#         break\n",
        "#     response = graph.invoke({\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\")\n",
        "#     print(\"Assistant:\", response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "tYDgDToF6Pch"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}