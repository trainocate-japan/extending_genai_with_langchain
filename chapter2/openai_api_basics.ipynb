{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trainocate-japan/extending_genai_with_langchain/blob/main/openai_api_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 0: ハンズオンの準備\n",
        "---"
      ],
      "metadata": {
        "id": "aeU0VqdXy8kg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API キーの設定\n",
        "*  左ナビゲーションで [**シークレット**] アイコン (鍵形のアイコン) をクリックします。\n",
        "*  [**新しいシークレットを追加**] をクリックし、`OPENAI_API_KEY` の [**値**] に指定されたキーを入力します。\n",
        "*  入力が完了したら、下のセルを実行します。"
      ],
      "metadata": {
        "id": "f58Tk1yFfJgh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4oSu5DqWgpG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzrWQTLn70Ra"
      },
      "source": [
        "# Section 1: トークン\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6fSq7bc8DES"
      },
      "source": [
        "## Tokenizerとtiktoken\n",
        "- LLM などの自然言語処理を行う機械学習モデルは、テキストをトークンという単位で処理する。\n",
        "- テキストデータなどをトークン化 (tokenize) するプログラムを **Tokenizer** という。\n",
        "- トークン化の仕方や入力可能なトークン数は LLM によって異なり、入力するトークン数に応じて API 利用料金が課金される。\n",
        "- **tiktoken** は OSS の高速な Tokenizer である。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MPred-0se6z"
      },
      "outputs": [],
      "source": [
        "# !pip -q install tiktoken==0.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCcxGOsIeksm"
      },
      "outputs": [],
      "source": [
        "!pip -q install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze | grep tiktoken"
      ],
      "metadata": {
        "id": "dJwNysHKOkrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWdpn2pw8NGp"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "text = \"It’s easy to make something cool with LLMs, but very hard to make something production-ready with them.\"\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
        "tokens = encoding.encode(text)\n",
        "print(len(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwIhYtWcshOY"
      },
      "outputs": [],
      "source": [
        "text = \"LLMを使ってクールなものを作るのは簡単だが、プロダクションで使えるものを作るのは非常に難しい。\"\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
        "tokens = encoding.encode(text)\n",
        "print(len(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P56iAwzT8Xmq"
      },
      "source": [
        "# Section 2: OpenAI API の利用\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0l8ptIe8iH5"
      },
      "source": [
        "## Chat Completions API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_R8jT7MNRC9t"
      },
      "outputs": [],
      "source": [
        "# !pip install openai==1.40.8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install openai"
      ],
      "metadata": {
        "id": "93qEpG4ZhPZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze | grep openai"
      ],
      "metadata": {
        "id": "ckL-ONQNOo1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTD-Xe9G8r6w"
      },
      "source": [
        "### Chat Completions APIの呼び出し"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHJUSC61Wg_y"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hello! I'm John.\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2THywRt8t0F"
      },
      "source": [
        "### 会話履歴を踏まえた応答を得る"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yk5Cc6rtWtub"
      },
      "outputs": [],
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Hello! I'm John.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Hello John! How can I assist you today?\"},\n",
        "        {\"role\": \"user\", \"content\": \"Do you know my name?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKRqvj0u8xWL"
      },
      "source": [
        "### ストリーミングで応答を得る"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7J2Gq9PYPBA"
      },
      "outputs": [],
      "source": [
        "stream = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"あなたは AI や機械学習に精通したプロフェッショナルです。\"},\n",
        "        {\"role\": \"user\", \"content\": \"AI とは何ですか。\"}\n",
        "  ],\n",
        "  stream=True\n",
        ")\n",
        "\n",
        "for chunk in stream:\n",
        "    if chunk.choices[0].delta.content is not None:\n",
        "        print(chunk.choices[0].delta.content, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrlT300r83MS"
      },
      "source": [
        "# Section 3: Function calling\n",
        "---\n",
        "Function Calling に対応しているモデルでは、利用可能な関数の情報をモデルに渡すことで、モデルに必要に応じた関数の利用を選択させることができる。\n",
        "\n",
        "(※ 以下では [OpenAI の公式ドキュメント](https://platform.openai.com/docs/guides/function-calling) をもとに一部改変したコードを使用している)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 関数を用意する  \n",
        "天気予報の情報を出力する関数  \n",
        "(実際に外部の天気予報サービスを利用するのではなく、既定の予報を返す疑似的な天気予報の関数)"
      ],
      "metadata": {
        "id": "4-ujhSxGPQtL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K97Pbcw3bly8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def get_current_weather(location, unit=\"celsius\"):\n",
        "    weather_info = {\n",
        "        \"location\": location,\n",
        "        \"temperature\": \"25\",\n",
        "        \"unit\": \"celsius\",\n",
        "        \"forecast\": [\"sunny\", \"windy\"],\n",
        "    }\n",
        "    return json.dumps(weather_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 関数のリストを定義する\n",
        "- 利用可能な関数のリストを定義する。  \n",
        "- それぞれの関数については、辞書で関数名や関数についての説明、関数を呼び出す際のパラメータ等を定義する。  \n",
        "- 下の例では、`tools` という名前のリストに要素として関数が 1 つだけ入っている。"
      ],
      "metadata": {
        "id": "gYGMoEgxlSOD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgIGMKtBgeGj"
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_current_weather\",\n",
        "            \"description\": \"Get the current weather in a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and state, e.g. Tokyo\",\n",
        "                    },\n",
        "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "                },\n",
        "                \"required\": [\"location\"],\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 関数のリストを渡して LLM を呼び出す"
      ],
      "metadata": {
        "id": "rPOkQw20QqrT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO-VYo7tghih"
      },
      "outputs": [],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Tokyo?\"}]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
        ")\n",
        "\n",
        "print(response.choices[0].message)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.tool_calls)"
      ],
      "metadata": {
        "id": "h_9V1fGlR-g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.tool_calls[0].function.name)\n",
        "print(response.choices[0].message.tool_calls[0].function.arguments)"
      ],
      "metadata": {
        "id": "JMVsVq0pUfkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- LLM が関数を使用することを選択した場合、使用する関数の名前や関数を呼び出す際のパラメータを回答する。\n",
        "- LLM は `tools` で定義されている関数の `name` や `description` 、`parameters` を参照して回答を生成する。"
      ],
      "metadata": {
        "id": "M4ycwjPEYxlv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 関数を実行する  \n",
        "- 上記の LLM の回答から関数名やパラメータを取得し、関数を実行する"
      ],
      "metadata": {
        "id": "FfaJaXAWZwP8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7LcVydmhlp0"
      },
      "outputs": [],
      "source": [
        "response_message = response.choices[0].message\n",
        "tool_call = response_message.tool_calls[0]\n",
        "\n",
        "available_functions = {\n",
        "    \"get_current_weather\": get_current_weather,\n",
        "}\n",
        "messages.append(response_message)\n",
        "function_name = tool_call.function.name\n",
        "function_to_call = available_functions[function_name]\n",
        "function_args = json.loads(tool_call.function.arguments)\n",
        "function_response = function_to_call(\n",
        "    location=function_args.get(\"location\"),\n",
        "    unit=function_args.get(\"unit\"),\n",
        ")\n",
        "\n",
        "print(function_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 関数の実行結果を `messages` に追加する"
      ],
      "metadata": {
        "id": "IihZ_KKdaWXR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe80yJNwjEJy"
      },
      "outputs": [],
      "source": [
        "messages.append({\n",
        "    \"tool_call_id\": tool_call.id,\n",
        "    \"role\": \"tool\",\n",
        "    \"name\": function_name,\n",
        "    \"content\": function_response,\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `messages` を渡して LLM を再度呼び出す"
      ],
      "metadata": {
        "id": "MBGoxlj6af3t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9QBhpRtgtSW"
      },
      "outputs": [],
      "source": [
        "second_response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=messages,\n",
        ")\n",
        "\n",
        "print(second_response.choices[0].message)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2wGUDo83qQy9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
